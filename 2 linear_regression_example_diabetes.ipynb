{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9ad028a",
      "metadata": {
        "id": "b9ad028a"
      },
      "source": [
        "# Introduction to Scikit-learn (sklearn) Datasets\n",
        "\n",
        "## Plus doing linear and polynomial regression using Scikit-learn\n",
        "\n",
        "- Michael Fairbank 2022\n",
        "- The purpose of this notebook is to teach the basics of using Sklearn to do data fitting and inspect the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eec1c33c",
      "metadata": {
        "id": "eec1c33c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99267bc8",
      "metadata": {
        "id": "99267bc8"
      },
      "source": [
        "The Scikit-learn package comes with some standard datasets.  We will load the \"diabetes\" dataset as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48ccfe4b",
      "metadata": {
        "id": "48ccfe4b",
        "outputId": "adaff216-7cee-4883-d6dc-6f17a413dea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data':           age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
            "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
            "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
            "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
            "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
            "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
            "\n",
            "           s4        s5        s6  \n",
            "0   -0.002592  0.019908 -0.017646  \n",
            "1   -0.039493 -0.068330 -0.092204  \n",
            "2   -0.002592  0.002864 -0.025930  \n",
            "3    0.034309  0.022692 -0.009362  \n",
            "4   -0.002592 -0.031991 -0.046641  \n",
            "..        ...       ...       ...  \n",
            "437 -0.002592  0.031193  0.007207  \n",
            "438  0.034309 -0.018118  0.044485  \n",
            "439 -0.011080 -0.046879  0.015491  \n",
            "440  0.026560  0.044528 -0.025930  \n",
            "441 -0.039493 -0.004220  0.003064  \n",
            "\n",
            "[442 rows x 10 columns], 'target': 0      151.0\n",
            "1       75.0\n",
            "2      141.0\n",
            "3      206.0\n",
            "4      135.0\n",
            "       ...  \n",
            "437    178.0\n",
            "438    104.0\n",
            "439    132.0\n",
            "440    220.0\n",
            "441     57.0\n",
            "Name: target, Length: 442, dtype: float64, 'frame':           age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
            "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
            "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
            "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
            "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
            "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
            "\n",
            "           s4        s5        s6  target  \n",
            "0   -0.002592  0.019908 -0.017646   151.0  \n",
            "1   -0.039493 -0.068330 -0.092204    75.0  \n",
            "2   -0.002592  0.002864 -0.025930   141.0  \n",
            "3    0.034309  0.022692 -0.009362   206.0  \n",
            "4   -0.002592 -0.031991 -0.046641   135.0  \n",
            "..        ...       ...       ...     ...  \n",
            "437 -0.002592  0.031193  0.007207   178.0  \n",
            "438  0.034309 -0.018118  0.044485   104.0  \n",
            "439 -0.011080 -0.046879  0.015491   132.0  \n",
            "440  0.026560  0.044528 -0.025930   220.0  \n",
            "441 -0.039493 -0.004220  0.003064    57.0  \n",
            "\n",
            "[442 rows x 11 columns], 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'diabetes_data.csv.gz', 'target_filename': 'diabetes_target.csv.gz', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "diabetes=datasets.load_diabetes(as_frame=True)\n",
        "print(diabetes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abaabd9",
      "metadata": {
        "id": "4abaabd9"
      },
      "source": [
        "As you see the loaded diabetes variable is a dictionary.  \n",
        "- Alter the code above to just print out the \"diabetes.DESCR\" field to learn about what the diabetes dataset consists of."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41574b87",
      "metadata": {
        "id": "41574b87"
      },
      "source": [
        "The \"diabetes.data\" field contains the dataframe.   But this omits the data targets - the code below adds this \"target\" column into the dataframe, so we can work with it more easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfa4491",
      "metadata": {
        "id": "9dfa4491"
      },
      "outputs": [],
      "source": [
        "df=diabetes.data\n",
        "df[\"disease_progression\"]=diabetes.target\n",
        "diabetes.data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7999cb32",
      "metadata": {
        "id": "7999cb32"
      },
      "source": [
        "## Question: \n",
        "- How many rows of data are there in the diabetes dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ef0788",
      "metadata": {
        "id": "b4ef0788"
      },
      "source": [
        "## Linear Regression, using a test set\n",
        "\n",
        "We'll do a regression task on two of the columns, i.e. bmi versus disease_progression, to investigate if there is a link.\n",
        "\n",
        "- When training a regression model (or any machine-learning model), it's a good idea to only train on a subset of the data (the \"training set\") and keep part of the data separate to test on later (the \"test set\" or \"validation set\")\n",
        "\n",
        "- We'll hold out the last 60 data points for the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1277e3e2",
      "metadata": {
        "id": "1277e3e2"
      },
      "outputs": [],
      "source": [
        "# Use only one feature\n",
        "diabetes_X = np.reshape(df[[\"bmi\"]].values,[-1,1])\n",
        "#diabetes_X=np.concatenate([diabetes_X,diabetes_X**2],axis=1)\n",
        "diabetes_y = df[\"disease_progression\"].values\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-60]\n",
        "diabetes_X_test = diabetes_X[-60:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes_y[:-60]\n",
        "diabetes_y_test = diabetes_y[-60:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc3b0cc3",
      "metadata": {
        "id": "cc3b0cc3"
      },
      "source": [
        "Plot our training and test data points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a2b5a2",
      "metadata": {
        "id": "e5a2b5a2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test[:,0], diabetes_y_test, label=\"test\")\n",
        "plt.scatter(diabetes_X_train[:,0], diabetes_y_train, label=\"train\")\n",
        "plt.xlabel(\"BMI\")\n",
        "plt.ylabel(\"Disease Progression\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb417c2c",
      "metadata": {
        "id": "cb417c2c"
      },
      "source": [
        "Now we'll apply a very simple model (linear regression) to plot a straight line through the training points\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html for further details and options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8621f43a",
      "metadata": {
        "id": "8621f43a"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred_test = regr.predict(diabetes_X_test)\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regr.coef_, regr.intercept_)\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test[:,0], diabetes_y_test, label=\"test\")\n",
        "x_range=np.linspace(diabetes_X_train.min(),diabetes_X_train.max(),50).reshape(-1, 1)\n",
        "plt.plot(x_range, regr.predict(x_range), color=\"blue\", linewidth=3) # Plot the regression line\n",
        "plt.xlabel(\"BMI\")\n",
        "plt.ylabel(\"Disease Progression\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf36f182",
      "metadata": {
        "id": "cf36f182"
      },
      "source": [
        "## Using metrics \n",
        "\n",
        "Scikit-learn includes metrics you can use to quantify how well your line-of-best fit fits the data.\n",
        "\n",
        "Note that mean-squared-error  is defined by $MSE=\\frac{1}{n}\\sum_{i=1}^n (y\\_pred(i)-y\\_true(i))^2$.\n",
        "\n",
        "The Coefficient of Determination is defined by $1-\\frac{MSE}{\\frac{1}{n}\\sum_{i=1}^n (y\\_true(i)-\\overline{y})^2$.}$, where $\\overline{y}$ is the average of $y\\_true$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b1d414",
      "metadata": {
        "id": "59b1d414"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred_test))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"R2 Score (Coefficient of determination) on test set: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77832629",
      "metadata": {
        "id": "77832629"
      },
      "source": [
        "## Questions \n",
        "\n",
        "- Modify the above code to print the metrics also on the training set, and compare the two.  \n",
        "- Which result is better - the test set or the training set.\n",
        "- What is the best possible value that Coefficient of Determination can ever be (in a perfect model)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10c0228",
      "metadata": {
        "id": "b10c0228"
      },
      "source": [
        "## Plotting predicted output versus true outputs\n",
        "\n",
        "If the predictions match the true labels, then all the pints of predicted output versus actual output should line up nicely on the line y=x.  \n",
        "\n",
        "- this is a nice trick for visualising something when there are more than 1 dimension in the input data (e.g. if we were doing multi-variate regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffc4484",
      "metadata": {
        "id": "0ffc4484"
      },
      "outputs": [],
      "source": [
        "y_range=np.linspace(diabetes_y_train.min(),diabetes_y_train.max(),50)\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_y_test, diabetes_y_pred_test, label=\"test\")\n",
        "plt.plot(y_range, y_range, label=\"y=x\")\n",
        "plt.xlabel(\"Actual Disease Progression\")\n",
        "plt.ylabel(\"Predicted Disease Progression\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e869ced",
      "metadata": {
        "id": "9e869ced"
      },
      "source": [
        "## Polynomial regression\n",
        "\n",
        "We have just attempted linear regression, i.e. finding \"$y=mx+c$\" through the datapoints.\n",
        "\n",
        "- Now we can switch to polynomial regression.  This is finding an equation \"$y=m_1 x+m_2 x^2+m_3 x^3+c$\" through the datapoints.\n",
        "\n",
        "- Note that polynomial regression is linear regression but where we use extra input features $x$, $x^2$, $x^3$, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0074b7e",
      "metadata": {
        "id": "e0074b7e"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
        "poly_features = poly.fit_transform(diabetes_X_train)\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(poly_features, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(poly.fit_transform(diabetes_X_test))\n",
        "\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regr.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"R2 Score (Coefficient of determination) on test set: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test[:,0], diabetes_y_test, label=\"test\")\n",
        "x_range=np.linspace(diabetes_X_train.min(),diabetes_X_train.max(),50).reshape(-1, 1)\n",
        "plt.plot(x_range, regr.predict(poly.fit_transform(x_range)), color=\"blue\", linewidth=3) # Plot the regression line\n",
        "plt.xlabel(\"BMI\")\n",
        "plt.ylabel(\"Disease Progression\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04d553f",
      "metadata": {
        "id": "c04d553f"
      },
      "source": [
        "## Questions:\n",
        "\n",
        "- Modify the code above to change the degree of the polynomial regression to 1, 2 and 5.\n",
        "- Modify the code to print separate metrics on the training and test sets.\n",
        "- If the degree of the polynomial is N, how many \"coefficients\" are printed in the code above?\n",
        "- Modify the code above to also print the y-intercept for the regression curve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5fef662",
      "metadata": {
        "id": "a5fef662"
      },
      "source": [
        "## Multiple input features (Multi-variate regression)\n",
        "\n",
        "Previosly we just looked at how one variable (BMI) correlates with another variable (Disease_progression).  \n",
        "\n",
        "Maybe we can do better at predicting disease progression if we use more than one input variable.    This leads us to try multivariate regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8036b1ea",
      "metadata": {
        "id": "8036b1ea"
      },
      "outputs": [],
      "source": [
        "# Use only one feature\n",
        "diabetes_X3 = np.reshape(df[[\"bmi\",\"bp\",\"age\"]].values,[-1,3])\n",
        "#diabetes_X=np.concatenate([diabetes_X,diabetes_X**2],axis=1)\n",
        "diabetes_y = df[\"disease_progression\"].values\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X3_train = diabetes_X3[:-60]\n",
        "diabetes_X3_test = diabetes_X3[-60:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes_y[:-60]\n",
        "diabetes_y_test = diabetes_y[-60:]\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=1, include_bias=False)\n",
        "poly_features = poly.fit_transform(diabetes_X3_train)\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(poly_features, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred_test = regr.predict(poly.fit_transform(diabetes_X3_test))\n",
        "diabetes_y_pred_train = regr.predict(poly.fit_transform(diabetes_X3_train))\n",
        "#x_range=np.linspace(diabetes_X_train.min(),diabetes_X_train.max(),50)\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regr.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error (test set): %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred_test))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"R2 Score (Coefficient of determination) (test set): %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred_test))\n",
        "print(\"Mean squared error (training set): %.2f\" % mean_squared_error(diabetes_y_train, diabetes_y_pred_train))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"R2 Score (Coefficient of determination) (training set): %.2f\" % r2_score(diabetes_y_train, diabetes_y_pred_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7c3e5d",
      "metadata": {
        "id": "ca7c3e5d"
      },
      "source": [
        "As multivariate regression requires higher dimensions to view the input plane, instead we'll just plot the output prediction versus actual prediction\n",
        "\n",
        "- and hope that they line up on $y=x$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e55bd1",
      "metadata": {
        "id": "52e55bd1"
      },
      "outputs": [],
      "source": [
        "y_range=np.linspace(diabetes_y_train.min(),diabetes_y_train.max(),50)\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_y_test, diabetes_y_pred_test, label=\"test\")\n",
        "plt.scatter(diabetes_y_train, diabetes_y_pred_train, label=\"train\")\n",
        "plt.plot(y_range, y_range, label=\"y=x\")\n",
        "plt.xlabel(\"Actual Disease Progression\")\n",
        "plt.ylabel(\"Predicted Disease Progression\")\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16e3cbc5",
      "metadata": {
        "id": "16e3cbc5"
      },
      "source": [
        "## Questions:\n",
        "\n",
        "- In general, are the metrics better on the test set or the training set?\n",
        "\n",
        "- For the polynomial regression method, try to plot a graph (below) of R2 Score on the y-axis versus the polynomial degree on the x-axis.  Show 2 curves, one for test set and one for training set.  Try to collect all of the data through polynomial degrees 1,2,3,4,5,6,7 in a single python for loop.\n",
        "\n",
        "- What is the best regression method you can find to get the best performance on the test set?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "2 linear_regression_example_diabetes.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}